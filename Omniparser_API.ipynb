{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bT9g3LN1okKA"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/microsoft/OmniParser.git\n",
        "%cd OmniParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGHjAjM4op_B"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDdp7dcbosKc"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!mkdir -p weights/icon_detect weights/icon_caption\n",
        "\n",
        "!huggingface-cli download microsoft/OmniParser-v2.0 icon_detect/train_args.yaml --local-dir weights/icon_detect --local-dir-use-symlinks False\n",
        "!huggingface-cli download microsoft/OmniParser-v2.0 icon_detect/model.pt --local-dir weights/icon_detect --local-dir-use-symlinks False\n",
        "!huggingface-cli download microsoft/OmniParser-v2.0 icon_detect/model.yaml --local-dir weights/icon_detect --local-dir-use-symlinks False\n",
        "\n",
        "!huggingface-cli download microsoft/OmniParser-v2.0 icon_caption/config.json --local-dir weights/icon_caption --local-dir-use-symlinks False\n",
        "!huggingface-cli download microsoft/OmniParser-v2.0 icon_caption/generation_config.json --local-dir weights/icon_caption --local-dir-use-symlinks False\n",
        "!huggingface-cli download microsoft/OmniParser-v2.0 icon_caption/model.safetensors --local-dir weights/icon_caption --local-dir-use-symlinks False\n",
        "\n",
        "!mv weights/icon_caption weights/icon_caption_florence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZg3SSse148q"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -U numpy\n",
        "\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qvi8r8M0ov2x"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/OmniParser')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvafgEWw0Pt_"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import TypedDict\n",
        "from typing import List\n",
        "\n",
        "class BBox(TypedDict):\n",
        "    x: float\n",
        "    y: float\n",
        "    interactivity: bool\n",
        "    content: str\n",
        "\n",
        "class ImageProcessingResponse(TypedDict):\n",
        "    img: str\n",
        "    bboxes: List[BBox]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GNHt0onpLrY"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install fastapi uvicorn nest-asyncio pyngrok python-multipart pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QspqmsPMEGrc"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "import uvicorn\n",
        "from fastapi import FastAPI, UploadFile, File\n",
        "from pydantic import BaseModel\n",
        "from typing import List\n",
        "from PIL import Image\n",
        "import io\n",
        "from pyngrok import ngrok\n",
        "from OmniParser.util.utils import get_som_labeled_img, check_ocr_box, get_caption_model_processor, get_yolo_model\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "from rich import print\n",
        "\n",
        "device = 'cuda'\n",
        "som_model = get_yolo_model(model_path='/content/OmniParser/weights/icon_detect/icon_detect/model.pt')\n",
        "som_model.to(device)\n",
        "print('model to {}'.format(device))\n",
        "caption_model_processor = get_caption_model_processor(model_name=\"florence2\", model_name_or_path='/content/OmniParser/weights/icon_caption_florence/icon_caption/')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6Af3bjXpM-r"
      },
      "outputs": [],
      "source": [
        "nest_asyncio.apply()\n",
        "app = FastAPI()\n",
        "\n",
        "@app.post(\"/process_image\", response_model=ImageProcessingResponse)\n",
        "async def process_image(file: UploadFile = File(...)):\n",
        "    contents = await file.read()\n",
        "    image = Image.open(io.BytesIO(contents)).convert(\"RGB\")\n",
        "    temp_path = \"/content/temp_image.jpg\"\n",
        "    image.save(temp_path)\n",
        "\n",
        "    ocr_bbox_rslt, _ = check_ocr_box(\n",
        "        temp_path,\n",
        "        display_img=False,\n",
        "        output_bb_format='xyxy',\n",
        "        goal_filtering=None,\n",
        "        easyocr_args={'paragraph': False, 'text_threshold': 0.9}\n",
        "    )\n",
        "    text, ocr_bbox = ocr_bbox_rslt\n",
        "\n",
        "    dino_labeled_img, _, parsed_content_list = get_som_labeled_img(\n",
        "        temp_path,\n",
        "        som_model,\n",
        "        BOX_TRESHOLD=0.03,\n",
        "        output_coord_in_ratio=False,\n",
        "        ocr_bbox=ocr_bbox,\n",
        "        draw_bbox_config={\n",
        "            'text_scale': 0.5,\n",
        "            'text_thickness': 1,\n",
        "            'text_padding': 1,\n",
        "            'thickness': 1\n",
        "        },\n",
        "        caption_model_processor=caption_model_processor,\n",
        "        ocr_text=text,\n",
        "        iou_threshold=0.1\n",
        "    )\n",
        "\n",
        "    icons_data = [\n",
        "        BBox(\n",
        "            x=(item['bbox'][0] + item['bbox'][2]) / 2,\n",
        "            y=(item['bbox'][1] + item['bbox'][3]) / 2,\n",
        "            interactivity=item['interactivity'],\n",
        "            content=item['content'].strip(),\n",
        "        )\n",
        "        for item in parsed_content_list\n",
        "    ]\n",
        "    return {\n",
        "        \"img\": dino_labeled_img,\n",
        "        \"bboxes\": icons_data\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnc8ell73m0l"
      },
      "outputs": [],
      "source": [
        "!ngrok config add-authtoken 2vcsXmkdaOyWc8cnxRS9Hs5c5aA_7jJPAhNdNzFaGthVdu5op"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import time\n",
        "\n",
        "ngrok.kill()\n",
        "time.sleep(2)\n",
        "\n",
        "public_url = ngrok.connect(8000)\n",
        "print(\" URL:\", public_url.public_url)\n",
        "\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
      ],
      "metadata": {
        "id": "enQy28HpkEQi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}